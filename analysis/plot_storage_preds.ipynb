{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%cd ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import itertools\n",
    "import os\n",
    "from typing import Literal\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import distributions as tdist, Tensor\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from models.gaussian import GaussianRegressor, GaussianRegressorSplit, train_gaussian_regressor_custom\n",
    "from storage.data import get_loaders, get_tensors, get_train_calib_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = 101\n",
    "Y_DIM = 24\n",
    "MAX_EPOCHS = 500\n",
    "BATCH_SIZE = 256\n",
    "SHUFFLE = False\n",
    "SEEDS = range(10)\n",
    "\n",
    "if SHUFFLE:\n",
    "    out_dir = 'out/storage_gaussian_custom_shuffle/'\n",
    "else:\n",
    "    out_dir = 'out/storage_gaussian_custom/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_dates_to_hourly(dates: np.ndarray) -> pd.DatetimeIndex:\n",
    "    oneday = pd.Timedelta(days=1)\n",
    "    hourly_dts: list[pd.Timestamp] = []\n",
    "    for date in dates:\n",
    "        hourly_range = pd.date_range(start=date, end=date + oneday, freq='h', inclusive='left')\n",
    "        hourly_dts.extend(hourly_range)\n",
    "    return pd.DatetimeIndex(hourly_dts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensors, y_info = get_tensors(shuffle=SHUFFLE, log_prices=False)\n",
    "assert isinstance(y_info, tuple)\n",
    "y_mean, y_std = y_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model_preds(\n",
    "    model: GaussianRegressorSplit,\n",
    "    tensors: dict[str, Tensor | np.ndarray],\n",
    "    unstandardize: tuple[np.ndarray, np.ndarray] | Literal['log'] | None,\n",
    "    plot_std: bool = False,\n",
    "    num_samples: int = 0,\n",
    "    split: str = 'traincalib',\n",
    "    date_range: tuple[str, str] | tuple[datetime.date, datetime.date] | None = ('2014-01-01', '2014-04-15'),\n",
    ") -> plt.Axes:\n",
    "    X, Y, dates = tensors[f'X_{split}'], tensors[f'Y_{split}'], tensors[f'date_{split}']\n",
    "    assert isinstance(X, Tensor)\n",
    "    assert isinstance(Y, Tensor)\n",
    "    assert isinstance(dates, np.ndarray)\n",
    "\n",
    "    datetimes = expand_dates_to_hourly(dates)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        loc, scale_tril = model(X)\n",
    "    pred_dist = tdist.MultivariateNormal(loc=loc, scale_tril=scale_tril)\n",
    "\n",
    "    samples = None\n",
    "    if num_samples > 0:\n",
    "        samples = pred_dist.sample((num_samples,))  # shape [3, N, y_dim]\n",
    "\n",
    "    if unstandardize is None:\n",
    "        true_y = Y\n",
    "        pred_mean = loc\n",
    "        pred_std = pred_dist.stddev\n",
    "        pred_lo = pred_mean - 2 * pred_std\n",
    "        pred_hi = pred_mean + 2 * pred_std\n",
    "    elif unstandardize == 'log':\n",
    "        true_y = torch.exp(Y)\n",
    "        pred_mean = torch.exp(loc)\n",
    "        pred_lo = torch.exp(loc - 2 * pred_dist.stddev)\n",
    "        pred_hi = torch.exp(loc + 2 * pred_dist.stddev)\n",
    "        if samples is not None:\n",
    "            samples = torch.exp(samples)\n",
    "    else:\n",
    "        y_mean, y_std = torch.from_numpy(unstandardize[0]), torch.from_numpy(unstandardize[1])\n",
    "        true_y = Y * y_std + y_mean\n",
    "        pred_mean = loc * y_std + y_mean\n",
    "        pred_std = pred_dist.stddev * y_std\n",
    "        pred_lo = pred_mean - 2 * pred_std\n",
    "        pred_hi = pred_mean + 2 * pred_std\n",
    "        if samples is not None:\n",
    "            samples = samples * y_std + y_mean\n",
    "\n",
    "    # reshape from [N, y_dim] to [N*y_dim]\n",
    "    true_y = true_y.reshape(-1).numpy()\n",
    "    pred_mean = pred_mean.reshape(-1).numpy()\n",
    "    pred_lo = pred_lo.reshape(-1).numpy()\n",
    "    pred_hi = pred_hi.reshape(-1).numpy()\n",
    "    if samples is not None:\n",
    "        samples = samples.reshape(3, -1).numpy()\n",
    "\n",
    "    pred_df = pd.DataFrame(index=datetimes, data={\n",
    "        'y': true_y,\n",
    "        'ypred_mean': pred_mean,\n",
    "        'ypred_lo': pred_lo,\n",
    "        'ypred_hi': pred_hi,\n",
    "    })\n",
    "    if samples is not None:\n",
    "        for i in range(num_samples):\n",
    "            pred_df[f'sample_{i}'] = samples[i]\n",
    "\n",
    "    if date_range is None:\n",
    "        subdf = pred_df\n",
    "    elif isinstance(date_range[0], str):\n",
    "        start_date = pd.Timestamp(date_range[0]).date()\n",
    "        end_date = pd.Timestamp(date_range[1]).date()\n",
    "        subdf = pred_df.loc[start_date:end_date]\n",
    "    else:\n",
    "        start_date, end_date = date_range\n",
    "        subdf = pred_df.loc[start_date:end_date]\n",
    "\n",
    "    _, ax = plt.subplots(figsize=(20, 4), tight_layout=True)\n",
    "    ax.plot(subdf.index, subdf['y'], label='true', color='black')\n",
    "    ax.plot(subdf.index, subdf['ypred_mean'], label=f'mean', alpha=0.7)\n",
    "    if samples is not None:\n",
    "        for i in range(num_samples):\n",
    "            ax.plot(subdf.index, subdf[f'sample_{i}'], alpha=0.3)\n",
    "    if plot_std:\n",
    "        ax.fill_between(subdf.index, subdf['ypred_lo'], subdf['ypred_hi'],\n",
    "                        label=r'$\\pm$ 2 std', alpha=0.3)\n",
    "    ax.legend()\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot pre-trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = 'traincalib'\n",
    "X, Y, dates = tensors[f'X_{split}'], tensors[f'Y_{split}'], tensors[f'date_{split}']\n",
    "\n",
    "assert isinstance(X, Tensor)\n",
    "assert isinstance(Y, Tensor)\n",
    "assert isinstance(dates, np.ndarray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datetimes = expand_dates_to_hourly(dates)\n",
    "true_y = torch.cat(tuple(Y)).numpy()\n",
    "pred_df = pd.DataFrame(index=datetimes, data={'y': true_y})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for seed in SEEDS:\n",
    "    model = GaussianRegressor(input_dim=INPUT_DIM, y_dim=Y_DIM)\n",
    "    ckpt_path = os.path.join(out_dir, f'gaussian_regressor_s{seed}.pt')\n",
    "    model.load_state_dict(torch.load(ckpt_path, weights_only=True))\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        loc, scale_tril = model(X)\n",
    "    pred_dist = tdist.MultivariateNormal(loc=loc, scale_tril=scale_tril)\n",
    "    pred_df[f'ypred_mean_s{seed}'] = torch.cat(tuple(loc)).numpy()\n",
    "    pred_df[f'ypred_std_s{seed}'] = torch.cat(tuple(pred_dist.stddev)).numpy()\n",
    "\n",
    "    nll = -pred_dist.log_prob(Y).mean().item()\n",
    "    print(f'seed {seed} nll {nll}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = pd.Timestamp('2014-01-01').date()\n",
    "end_date = pd.Timestamp('2014-04-15').date()\n",
    "subdf = pred_df.loc[start_date:end_date]\n",
    "# subdf = pred_df\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 4), tight_layout=True)\n",
    "ax.plot(subdf.index, subdf['y'], label='true', color='black')\n",
    "for seed in [2]:\n",
    "    ax.plot(subdf.index, subdf[f'ypred_mean_s{seed}'], label=f's{seed} mean', alpha=0.3)\n",
    "    ax.plot(subdf.index, subdf[f'ypred_std_s{seed}'], label=f's{seed} std', alpha=0.3)\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1\n",
    "model = GaussianRegressorSplit(input_dim=INPUT_DIM, y_dim=Y_DIM)\n",
    "# with torch.no_grad():\n",
    "#     model.diag_net.weight.fill_(0.)\n",
    "#     model.diag_net.bias.fill_(1.)\n",
    "#     model.loc_net.weight.fill_(0.)\n",
    "#     model.loc_net.bias.fill_(0.)\n",
    "ckpt_path = os.path.join(out_dir, f'gaussian_regressor_s{seed}.pt')\n",
    "model.load_state_dict(torch.load(ckpt_path, weights_only=True))\n",
    "ax = plot_model_preds(\n",
    "    model=model, tensors=tensors, unstandardize=y_info,  # y_info,  # y_info, (y_mean_tch, y_std_tch),\n",
    "    plot_samples=False, plot_std=True, split='traincalib',\n",
    "    date_range=('2014-01-01', '2014-02-15')\n",
    ")\n",
    "# ax.set(ylim=(-0, 400))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Smart\n",
    "\n",
    "Option A\n",
    "1. train with NLL\n",
    "2. Fix (embed, covariance), train mean\n",
    "3. Fix (embed, mean), train covariance\n",
    "\n",
    "Option B\n",
    "1. train with NLL-diag\n",
    "2. Fix (embed, mean), train covariance\n",
    "3. Fine tune NLL\n",
    "\n",
    "Option C\n",
    "1. train with NLL-diag\n",
    "2. Fine tune NLL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrs = 10. ** np.arange(-4, -1.4, 0.5)\n",
    "l2regs = [1e-4]\n",
    "# l2regs = [0, 1e-4, 1e-3, 1e-2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option A\n",
    "1. train with NLL\n",
    "2. Fix (embed, covariance), train mean\n",
    "3. Fix (embed, mean), train covariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'\n",
    "\n",
    "seed = 1\n",
    "tensors_cv, _ = get_train_calib_split(tensors, seed=seed)\n",
    "loaders = get_loaders(tensors_cv, batch_size=BATCH_SIZE)\n",
    "\n",
    "best_model = None\n",
    "best_hp = None\n",
    "best_val_loss = np.inf\n",
    "\n",
    "losses = []\n",
    "pbar = tqdm(itertools.product(lrs, l2regs), total=len(lrs) * len(l2regs))\n",
    "for lr, l2reg in pbar:\n",
    "    try:\n",
    "        model = GaussianRegressorSplit(input_dim=INPUT_DIM, y_dim=Y_DIM)\n",
    "        result = train_gaussian_regressor_custom(\n",
    "            model, loaders, loss_name='nll', max_epochs=MAX_EPOCHS, lr=lr, l2reg=l2reg,\n",
    "            return_best_model=True, device=device, show_pbar=True)\n",
    "        if result['val_loss'] < best_val_loss:\n",
    "            best_val_loss = result['val_loss']\n",
    "            best_hp = (lr, l2reg)\n",
    "            best_model = model\n",
    "        tqdm.write(f'(lr {lr:.3g}, l2reg {l2reg:.3g}) best epoch: {result[\"best_epoch\"]}, '\n",
    "                   f'val_loss: {result[\"val_loss\"]:.3f}, ')\n",
    "    except Exception as e:\n",
    "        tqdm.write(f'(lr {lr:.3g}, l2reg {l2reg:.3g}, seed {seed}) failed: {e}')\n",
    "        losses.append((lr, l2reg, seed, np.nan))\n",
    "\n",
    "assert best_model is not None\n",
    "# ckpt_path = os.path.join(out_dir, f'gaussian_regressor_s{seed}_nll.pt')\n",
    "# torch.save(best_model.cpu().state_dict(), ckpt_path)\n",
    "# print(f'Saved best model to {ckpt_path}')\n",
    "print(f'Best hp: lr={best_hp[0]}, l2reg={best_hp[1]}, val_loss={best_val_loss:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1\n",
    "model = GaussianRegressorSplit(input_dim=INPUT_DIM, y_dim=Y_DIM)\n",
    "ckpt_path = os.path.join(out_dir, f'gaussian_regressor_s{seed}.pt')\n",
    "model.load_state_dict(torch.load(ckpt_path, weights_only=True))\n",
    "ax = plot_model_preds(\n",
    "    model=model, tensors=tensors, unstandardize=y_info,  # y_info, (y_mean_tch, y_std_tch),\n",
    "    plot_std=True, split='traincalib',\n",
    "    date_range=('2012-01-01', '2012-09-01')\n",
    ")\n",
    "# ax.set(ylim=(-10, 2000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option B\n",
    "\n",
    "1. train with NLL\n",
    "2. Fix (embed, covariance), train mean\n",
    "3. Fix (embed, mean), train covariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "\n",
    "seed = 1\n",
    "tensors_cv, _ = get_train_calib_split(tensors, seed=seed)\n",
    "loaders = get_loaders(tensors_cv, batch_size=BATCH_SIZE)\n",
    "\n",
    "best_model = None\n",
    "best_hp = None\n",
    "best_val_loss = np.inf\n",
    "\n",
    "ckpt_path = os.path.join(out_dir, f'gaussian_regressor_s{seed}_nll.pt')\n",
    "\n",
    "losses = []\n",
    "pbar = tqdm(itertools.product(lrs, l2regs), total=len(lrs) * len(l2regs))\n",
    "l2reg = 0\n",
    "for lr in [1e-5, 1e-4, 1e-3, 1e-2, 1e-1]:\n",
    "    try:\n",
    "        model = GaussianRegressorSplit(input_dim=INPUT_DIM, y_dim=Y_DIM)\n",
    "        model.load_state_dict(torch.load(ckpt_path, weights_only=True))\n",
    "        result = train_gaussian_regressor_custom(\n",
    "            model, loaders, loss_name='nll', max_epochs=MAX_EPOCHS, lr=lr, l2reg=l2reg,\n",
    "            return_best_model=True, device=device, show_pbar=True, freeze=('embed', 'diag_net', 'scale_tril_net'))\n",
    "        if result['val_loss'] < best_val_loss:\n",
    "            best_val_loss = result['val_loss']\n",
    "            best_hp = (lr, l2reg)\n",
    "            best_model = model\n",
    "        tqdm.write(f'(lr {lr:.3g}, l2reg {l2reg:.3g}) best epoch: {result[\"best_epoch\"]}, '\n",
    "                   f'val_loss: {result[\"val_loss\"]:.3f}, ')\n",
    "    except Exception as e:\n",
    "        tqdm.write(f'(lr {lr:.3g}, l2reg {l2reg:.3g}, seed {seed}) failed: {e}')\n",
    "        losses.append((lr, l2reg, seed, np.nan))\n",
    "\n",
    "assert best_model is not None\n",
    "ckpt_path = os.path.join(out_dir, f'gaussian_regressor_s{seed}_nll_mean.pt')\n",
    "torch.save(best_model.cpu().state_dict(), ckpt_path)\n",
    "print(f'Saved best model to {ckpt_path}')\n",
    "print(f'Best hp: lr={best_hp[0]}, l2reg={best_hp[1]}, val_loss={best_val_loss:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1\n",
    "model = GaussianRegressorSplit(input_dim=INPUT_DIM, y_dim=Y_DIM)\n",
    "ckpt_path = os.path.join(out_dir, f'gaussian_regressor_s{seed}_nll_mean.pt')\n",
    "model.load_state_dict(torch.load(ckpt_path, weights_only=True))\n",
    "plot_model_preds(\n",
    "    model=model, tensors=tensors, unstandardize=(y_mean_tch, y_std_tch), plot_std=True, split='traincalib',\n",
    "    date_range=('2014-01-01', '2014-04-15')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "\n",
    "seed = 1\n",
    "tensors_cv, _ = get_train_calib_split(tensors, seed=seed)\n",
    "loaders = get_loaders(tensors_cv, batch_size=BATCH_SIZE)\n",
    "\n",
    "best_model = None\n",
    "best_hp = None\n",
    "best_val_loss = np.inf\n",
    "\n",
    "ckpt_path = os.path.join(out_dir, f'gaussian_regressor_s{seed}_nll.pt')\n",
    "\n",
    "losses = []\n",
    "pbar = tqdm(itertools.product(lrs, l2regs), total=len(lrs) * len(l2regs))\n",
    "l2reg = 0\n",
    "for lr in [1e-5, 1e-4, 1e-3, 1e-2, 1e-1]:\n",
    "    try:\n",
    "        model = GaussianRegressorSplit(input_dim=INPUT_DIM, y_dim=Y_DIM)\n",
    "        model.load_state_dict(torch.load(ckpt_path, weights_only=True))\n",
    "        result = train_gaussian_regressor_custom(\n",
    "            model, loaders, loss_name='mse', max_epochs=MAX_EPOCHS, lr=lr, l2reg=l2reg,\n",
    "            return_best_model=True, device=device, show_pbar=True, freeze=('embed', 'diag_net', 'scale_tril_net'))\n",
    "        if result['val_loss'] < best_val_loss:\n",
    "            best_val_loss = result['val_loss']\n",
    "            best_hp = (lr, l2reg)\n",
    "            best_model = model\n",
    "        tqdm.write(f'(lr {lr:.3g}, l2reg {l2reg:.3g}) best epoch: {result[\"best_epoch\"]}, '\n",
    "                   f'val_loss: {result[\"val_loss\"]:.3f}, ')\n",
    "    except Exception as e:\n",
    "        tqdm.write(f'(lr {lr:.3g}, l2reg {l2reg:.3g}, seed {seed}) failed: {e}')\n",
    "        losses.append((lr, l2reg, seed, np.nan))\n",
    "\n",
    "assert best_model is not None\n",
    "ckpt_path = os.path.join(out_dir, f'gaussian_regressor_s{seed}_nll_mse.pt')\n",
    "torch.save(best_model.cpu().state_dict(), ckpt_path)\n",
    "print(f'Saved best model to {ckpt_path}')\n",
    "print(f'Best hp: lr={best_hp[0]}, l2reg={best_hp[1]}, val_loss={best_val_loss:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1\n",
    "model = GaussianRegressorSplit(input_dim=INPUT_DIM, y_dim=Y_DIM)\n",
    "ckpt_path = os.path.join(out_dir, f'gaussian_regressor_s{seed}_nll_mse.pt')\n",
    "model.load_state_dict(torch.load(ckpt_path, weights_only=True))\n",
    "plot_model_preds(\n",
    "    model=model, tensors=tensors, unstandardize=(y_mean_tch, y_std_tch), plot_std=True, split='traincalib',\n",
    "    date_range=('2014-01-01', '2014-04-15')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc, scale_tril = model(tensors_cv['X_calib'])\n",
    "-tdist.MultivariateNormal(loc=loc, scale_tril=scale_tril).log_prob(tensors_cv['Y_calib']).mean().item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option C\n",
    "\n",
    "1. train mean with MSE\n",
    "2. Fix (embed, mean), train covariance\n",
    "3. Optionally fine tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'device'\n",
    "\n",
    "seed = 1\n",
    "tensors_cv, _ = get_train_calib_split(tensors, seed=seed)\n",
    "loaders = get_loaders(tensors_cv, batch_size=BATCH_SIZE)\n",
    "\n",
    "best_model = None\n",
    "best_hp = None\n",
    "best_val_loss = np.inf\n",
    "\n",
    "losses = []\n",
    "pbar = tqdm(itertools.product(lrs, l2regs), total=len(lrs) * len(l2regs))\n",
    "for lr, l2reg in pbar:\n",
    "    try:\n",
    "        model = GaussianRegressorSplit(input_dim=INPUT_DIM, y_dim=Y_DIM)\n",
    "        result = train_gaussian_regressor_custom(\n",
    "            model, loaders, loss_name='mse', max_epochs=MAX_EPOCHS, lr=lr, l2reg=l2reg,\n",
    "            return_best_model=True, device=device)\n",
    "        if result['val_loss'] < best_val_loss:\n",
    "            best_val_loss = result['val_loss']\n",
    "            best_hp = (lr, l2reg)\n",
    "            best_model = model\n",
    "        tqdm.write(f'(lr {lr:.3g}, l2reg {l2reg:.3g}) best epoch: {result[\"best_epoch\"]}, '\n",
    "                   f'val_loss: {result[\"val_loss\"]:.3f}, ')\n",
    "    except Exception as e:\n",
    "        tqdm.write(f'(lr {lr:.3g}, l2reg {l2reg:.3g}, seed {seed}) failed: {e}')\n",
    "        losses.append((lr, l2reg, seed, np.nan))\n",
    "\n",
    "assert best_model is not None\n",
    "ckpt_path = os.path.join(out_dir, f'gaussian_regressor_s{seed}_mse.pt')\n",
    "torch.save(best_model.cpu().state_dict(), ckpt_path)\n",
    "print(f'Saved best model to {ckpt_path}')\n",
    "print(f'Best hp: lr={best_hp[0]}, l2reg={best_hp[1]}, val_loss={best_val_loss:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1\n",
    "model = GaussianRegressorSplit(input_dim=INPUT_DIM, y_dim=Y_DIM)\n",
    "ckpt_path = os.path.join(out_dir, f'gaussian_regressor_s{seed}_mse.pt')\n",
    "model.load_state_dict(torch.load(ckpt_path, weights_only=True))\n",
    "plot_model_preds(\n",
    "    model=model, tensors=tensors, unstandardize=(y_mean_tch, y_std_tch),\n",
    "    plot_std=False, split='traincalib',\n",
    "    date_range=('2014-01-01', '2014-04-01')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_path = os.path.join(out_dir, f'gaussian_regressor_s{seed}_mse.pt')\n",
    "model = GaussianRegressorSplit(input_dim=INPUT_DIM, y_dim=Y_DIM)\n",
    "model.load_state_dict(torch.load(ckpt_path, weights_only=True))\n",
    "model.eval()\n",
    "loc, _ = model(tensors_cv['X_train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "\n",
    "seed = 1\n",
    "tensors_cv, _ = get_train_calib_split(tensors, seed=seed)\n",
    "loaders = get_loaders(tensors_cv, batch_size=BATCH_SIZE)\n",
    "\n",
    "best_model = None\n",
    "best_hp = None\n",
    "best_val_loss = np.inf\n",
    "\n",
    "# ckpt_path = os.path.join(out_dir, f'gaussian_regressor_s{seed}_mse.pt')\n",
    "\n",
    "losses = []\n",
    "pbar = tqdm(itertools.product(lrs, l2regs), total=len(lrs) * len(l2regs))\n",
    "l2reg = 1e-4\n",
    "for lr in [1e-5, 1e-4, 1e-3, 1e-2]:\n",
    "    try:\n",
    "        model = GaussianRegressorSplit(input_dim=INPUT_DIM, y_dim=Y_DIM)\n",
    "        # model.load_state_dict(torch.load(ckpt_path, weights_only=True))\n",
    "        # model.initialize_diag_bias(4.)\n",
    "        # with torch.no_grad():\n",
    "        #     torch.nn.init.normal_(model.scale_tril_net.weight, mean=0., std=5e-3)\n",
    "        #     torch.nn.init.normal_(model.scale_tril_net.bias, mean=0., std=5e-3)\n",
    "        result = train_gaussian_regressor_custom(\n",
    "            model, loaders, loss_name='mse_nll', max_epochs=MAX_EPOCHS, lr=lr, l2reg=l2reg,\n",
    "            return_best_model=True, device=device, show_pbar=True)\n",
    "        if result['val_loss'] < best_val_loss:\n",
    "            best_val_loss = result['val_loss']\n",
    "            best_hp = (lr, l2reg)\n",
    "            best_model = model\n",
    "        tqdm.write(f'(lr {lr:.3g}, l2reg {l2reg:.3g}) best epoch: {result[\"best_epoch\"]}, '\n",
    "                   f'val_loss: {result[\"val_loss\"]:.3f}, ')\n",
    "    except Exception as e:\n",
    "        tqdm.write(f'(lr {lr:.3g}, l2reg {l2reg:.3g}, seed {seed}) failed: {e}')\n",
    "        losses.append((lr, l2reg, seed, np.nan))\n",
    "\n",
    "assert best_model is not None\n",
    "ckpt_path = os.path.join(out_dir, f'gaussian_regressor_s{seed}_mse_nll.pt')\n",
    "torch.save(best_model.cpu().state_dict(), ckpt_path)\n",
    "print(f'Saved best model to {ckpt_path}')\n",
    "print(f'Best hp: lr={best_hp[0]}, l2reg={best_hp[1]}, val_loss={best_val_loss:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1\n",
    "model = GaussianRegressorSplit(input_dim=INPUT_DIM, y_dim=Y_DIM)\n",
    "ckpt_path = os.path.join(out_dir, f'gaussian_regressor_s{seed}_mse_nll.pt')\n",
    "model.load_state_dict(torch.load(ckpt_path, weights_only=True))\n",
    "plot_model_preds(\n",
    "    model=model, tensors=tensors, unstandardize=(y_mean_tch, y_std_tch),\n",
    "    plot_std=True, split='traincalib',\n",
    "    date_range=('2014-01-01', '2014-04-01')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option D\n",
    "- train with NLL diag\n",
    "- fine tune with NLL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'\n",
    "\n",
    "seed = 1\n",
    "tensors_cv, _ = get_train_calib_split(tensors, seed=seed)\n",
    "loaders = get_loaders(tensors_cv, batch_size=BATCH_SIZE)\n",
    "\n",
    "best_model = None\n",
    "best_hp = None\n",
    "best_val_loss = np.inf\n",
    "\n",
    "losses = []\n",
    "pbar = tqdm(itertools.product(lrs, l2regs), total=len(lrs) * len(l2regs))\n",
    "for lr, l2reg in pbar:\n",
    "    try:\n",
    "        model = GaussianRegressorSplit(input_dim=INPUT_DIM, y_dim=Y_DIM)\n",
    "        result = train_gaussian_regressor_custom(\n",
    "            model, loaders, loss_name='nll_diag', max_epochs=MAX_EPOCHS, lr=lr, l2reg=l2reg,\n",
    "            return_best_model=True, device=device)\n",
    "        if result['val_loss'] < best_val_loss:\n",
    "            best_val_loss = result['val_loss']\n",
    "            best_hp = (lr, l2reg)\n",
    "            best_model = model\n",
    "        tqdm.write(f'(lr {lr:.3g}, l2reg {l2reg:.3g}) best epoch: {result[\"best_epoch\"]}, '\n",
    "                   f'val_loss: {result[\"val_loss\"]:.3f}, ')\n",
    "    except Exception as e:\n",
    "        tqdm.write(f'(lr {lr:.3g}, l2reg {l2reg:.3g}, seed {seed}) failed: {e}')\n",
    "        losses.append((lr, l2reg, seed, np.nan))\n",
    "\n",
    "assert best_model is not None\n",
    "ckpt_path = os.path.join(out_dir, f'gaussian_regressor_s{seed}_nlldiag.pt')\n",
    "torch.save(best_model.cpu().state_dict(), ckpt_path)\n",
    "print(f'Saved best model to {ckpt_path}')\n",
    "print(f'Best hp: lr={best_hp[0]}, l2reg={best_hp[1]}, val_loss={best_val_loss:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1\n",
    "model = GaussianRegressorSplit(input_dim=INPUT_DIM, y_dim=Y_DIM)\n",
    "ckpt_path = os.path.join(out_dir, f'gaussian_regressor_s{seed}_nlldiag.pt')\n",
    "model.load_state_dict(torch.load(ckpt_path, weights_only=True))\n",
    "with torch.no_grad():\n",
    "    model.scale_tril_net.weight.fill_(0.)\n",
    "    model.scale_tril_net.bias.fill_(0.)\n",
    "ax = plot_model_preds(\n",
    "    model=model, tensors=tensors, unstandardize=y_info,  # y_info, (y_mean_tch, y_std_tch),\n",
    "    plot_std=True, split='traincalib',\n",
    "    date_range=('2014-03-01', '2014-03-15')\n",
    ")\n",
    "ax.set(ylim=(-10, 200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for seed in range(10):\n",
    "    ckpt_path = os.path.join(out_dir, f'gaussian_regressor_s{seed}_nlldiag.pt')\n",
    "    model = GaussianRegressorSplit(input_dim=INPUT_DIM, y_dim=Y_DIM)\n",
    "    model.load_state_dict(torch.load(ckpt_path, weights_only=True))\n",
    "    model.zero_scale_tril_net()\n",
    "    torch.save(model.state_dict(), ckpt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'\n",
    "\n",
    "seed = 3\n",
    "tensors_cv, _ = get_train_calib_split(tensors, seed=seed)\n",
    "loaders = get_loaders(tensors_cv, batch_size=-1)\n",
    "\n",
    "ckpt_path = os.path.join(out_dir, f'gaussian_regressor_s{seed}_nlldiag.pt')\n",
    "\n",
    "best_model = None\n",
    "best_hp = None\n",
    "best_val_loss = np.inf\n",
    "\n",
    "losses = []\n",
    "pbar = tqdm(itertools.product(lrs, l2regs), total=len(lrs) * len(l2regs))\n",
    "for lr, l2reg in pbar:\n",
    "    try:\n",
    "        model = GaussianRegressorSplit(input_dim=INPUT_DIM, y_dim=Y_DIM)\n",
    "        model.load_state_dict(torch.load(ckpt_path, weights_only=True))\n",
    "        model.zero_scale_tril_net()\n",
    "        result = train_gaussian_regressor_custom(\n",
    "            model, loaders, loss_name='nll', max_epochs=MAX_EPOCHS, lr=lr, l2reg=l2reg,\n",
    "            return_best_model=True, device=device, show_pbar=True)\n",
    "        if result['val_loss'] < best_val_loss:\n",
    "            best_val_loss = result['val_loss']\n",
    "            best_hp = (lr, l2reg)\n",
    "            best_model = model\n",
    "        tqdm.write(f'(lr {lr:.3g}, l2reg {l2reg:.3g}) best epoch: {result[\"best_epoch\"]}, '\n",
    "                   f'val_loss: {result[\"val_loss\"]:.3f}, ')\n",
    "    except Exception as e:\n",
    "        tqdm.write(f'(lr {lr:.3g}, l2reg {l2reg:.3g}, seed {seed}) failed: {e}')\n",
    "        losses.append((lr, l2reg, seed, np.nan))\n",
    "\n",
    "assert best_model is not None\n",
    "# ckpt_path = os.path.join(out_dir, f'gaussian_regressor_s{seed}_nlldiag_nll.pt')\n",
    "# torch.save(best_model.cpu().state_dict(), ckpt_path)\n",
    "# print(f'Saved best model to {ckpt_path}')\n",
    "print(f'Best hp: lr={best_hp[0]}, l2reg={best_hp[1]}, val_loss={best_val_loss:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.scale_tril_net.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1\n",
    "model = GaussianRegressorSplit(input_dim=INPUT_DIM, y_dim=Y_DIM)\n",
    "ckpt_path = os.path.join(out_dir, f'gaussian_regressor_s{seed}_nlldiag_nll.pt')\n",
    "model.load_state_dict(torch.load(ckpt_path, weights_only=True))\n",
    "ax = plot_model_preds(\n",
    "    model=model, tensors=tensors, unstandardize=y_info,  # y_info, (y_mean_tch, y_std_tch),\n",
    "    plot_std=True, split='traincalib',\n",
    "    date_range=('2014-03-01', '2014-03-15')\n",
    ")\n",
    "ax.set(ylim=(-10, 200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'\n",
    "\n",
    "seed = 1\n",
    "tensors_cv, _ = get_train_calib_split(tensors, seed=seed)\n",
    "loaders = get_loaders(tensors_cv, batch_size=1024)\n",
    "\n",
    "ckpt_path = os.path.join(out_dir, f'gaussian_regressor_s{seed}_nlldiag_nll.pt')\n",
    "\n",
    "best_model = None\n",
    "best_hp = None\n",
    "best_val_loss = np.inf\n",
    "\n",
    "losses = []\n",
    "pbar = tqdm(itertools.product(lrs, l2regs), total=len(lrs) * len(l2regs))\n",
    "for lr, l2reg in pbar:\n",
    "    try:\n",
    "        model = GaussianRegressorSplit(input_dim=INPUT_DIM, y_dim=Y_DIM)\n",
    "        model.load_state_dict(torch.load(ckpt_path, weights_only=True))\n",
    "        result = train_gaussian_regressor_custom(\n",
    "            model, loaders, loss_name='nll', max_epochs=MAX_EPOCHS, lr=lr, l2reg=l2reg,\n",
    "            return_best_model=True, device=device, show_pbar=True, cutoff=50)\n",
    "        if result['val_loss'] < best_val_loss:\n",
    "            best_val_loss = result['val_loss']\n",
    "            best_hp = (lr, l2reg)\n",
    "            best_model = model\n",
    "        tqdm.write(f'(lr {lr:.3g}, l2reg {l2reg:.3g}) best epoch: {result[\"best_epoch\"]}, '\n",
    "                   f'val_loss: {result[\"val_loss\"]:.3f}, ')\n",
    "    except Exception as e:\n",
    "        tqdm.write(f'(lr {lr:.3g}, l2reg {l2reg:.3g}, seed {seed}) failed: {e}')\n",
    "        losses.append((lr, l2reg, seed, np.nan))\n",
    "\n",
    "assert best_model is not None\n",
    "ckpt_path = os.path.join(out_dir, f'gaussian_regressor_s{seed}_nlldiag_nll_finetune.pt')\n",
    "torch.save(best_model.cpu().state_dict(), ckpt_path)\n",
    "print(f'Saved best model to {ckpt_path}')\n",
    "print(f'Best hp: lr={best_hp[0]}, l2reg={best_hp[1]}, val_loss={best_val_loss:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1\n",
    "model = GaussianRegressorSplit(input_dim=INPUT_DIM, y_dim=Y_DIM)\n",
    "ckpt_path = os.path.join(out_dir, f'gaussian_regressor_s{seed}_nlldiag_nll_finetune.pt')\n",
    "model.load_state_dict(torch.load(ckpt_path, weights_only=True))\n",
    "ax = plot_model_preds(\n",
    "    model=model, tensors=tensors, unstandardize=y_info,  # y_info, (y_mean_tch, y_std_tch),\n",
    "    plot_std=True, split='traincalib',\n",
    "    date_range=('2014-02-01', '2014-03-01')\n",
    ")\n",
    "ax.set(ylim=(-10, 250))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dauq",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
